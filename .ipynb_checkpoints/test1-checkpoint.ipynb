{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92cbe80b-02a4-4943-84de-b8b7f12f4677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me tell you a story...\n",
      "\n",
      "Once upon a time, in a small village nestled in the mountains, there lived a young girl named Mei. Mei was known throughout the village for her incredible talent â€“ she could talk to animals.\n",
      "\n",
      "As a child, Mei would spend hours playing with the animals on her family's farm, and as she grew older, she realized that they were actually listening to her and responding to what she said. The chickens would cluck in agreement, the cows would moo softly, and even the stubborn goats would nod their heads when Mei spoke.\n",
      "\n",
      "One day, a severe drought hit the land, and the crops began to wither and die. The villagers were worried, as they relied heavily on farming for their livelihood. Mei, feeling helpless, decided to take matters into her own hands. She gathered all of the animals from the farm and led them on a journey to find a hidden spring that was said to be deep in the forest.\n",
      "\n",
      "As she walked, Mei talked to the animals, explaining what they were doing and why it was important. The animals listened intently, their ears perked up and their eyes shining with understanding. When they finally reached the spring, Mei encouraged the animals to dig and uncover its source.\n",
      "\n",
      "With a collective effort from the animals, the spring began to flow again, bringing life-giving water back to the parched earth. The villagers were amazed as the crops began to grow once more, thanks to Mei's determination and her special gift with animals.\n",
      "\n",
      "From that day on, Mei was hailed as a hero in the village. People would come from all around to seek her help in communicating with their own pets, and soon, her fame spread throughout the region.\n",
      "\n",
      "As for Mei, she continued to use her gift to help those in need, always remembering that even the smallest creatures can have a big impact when working together... ğŸ°ğŸ’§\n",
      "\n",
      "What do you think? Would you like to hear another story? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const simpleChain = ollama.pipe(outputPrase)\n",
    "\n",
    "const stream = await simpleChain.invoke([\n",
    "     new HumanMessage(\"è®²ä¸ªæ•…äº‹\")\n",
    "])\n",
    "\n",
    "console.log(stream);\n",
    "\n",
    "// const stream = await simpleChain.stream([\n",
    "//      new HumanMessage(\"Tell me a joke\")\n",
    "// ])\n",
    "// for await (const chunk of stream){\n",
    "//     console.log(chunk)\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282ca258-7640-4085-ab68-28064a1de83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const greetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [],\n",
    "  template: \"hello world\",\n",
    "});\n",
    "const formattedGreetingPrompt = await greetingPrompt.format();\n",
    "\n",
    "console.log(formattedGreetingPrompt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d20103-8adb-4d1a-9ba7-120ed7216d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good morning, Kai {test}\n"
     ]
    }
   ],
   "source": [
    "const multiVariableGreetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [\"timeOfDay\", \"name\"],\n",
    "  template: \"good {timeOfDay}, {name} {{test}}\",\n",
    "});\n",
    "const formattedMultiVariableGreeting = await multiVariableGreetingPrompt.format({\n",
    "  timeOfDay: \"morning\",\n",
    "  name: \"Kai\",\n",
    "});\n",
    "\n",
    "console.log(formattedMultiVariableGreeting);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86555c54-cc7b-4541-b337-6e66083bd503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"timeOfDay\"\u001b[39m, \u001b[32m\"name\"\u001b[39m ]\n",
      "good morning, Kai\n"
     ]
    }
   ],
   "source": [
    "const autoInferTemplate = PromptTemplate.fromTemplate(\"good {timeOfDay}, {name}\");\n",
    "console.log(autoInferTemplate.inputVariables);\n",
    "\n",
    "const formattedAutoInferTemplate = await autoInferTemplate.format({\n",
    "  timeOfDay: \"morning\",\n",
    "  name: \"Kai\",\n",
    "});\n",
    "console.log(formattedAutoInferTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7def3380-cfc7-49f0-9529-9e0a478550cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä»Šå¤©æ˜¯2024/5/9ï¼Œæˆ‘ä»¬å»çˆ¬å±±ã€‚\n"
     ]
    }
   ],
   "source": [
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "const promptWithDate = new PromptTemplate({\n",
    "  template: \"ä»Šå¤©æ˜¯{date}ï¼Œ{activity}ã€‚\",\n",
    "  inputVariables: [\"date\", \"activity\"],\n",
    "});\n",
    "\n",
    "const partialedPromptWithDate = await promptWithDate.partial({\n",
    "  date: getCurrentDateStr,\n",
    "});\n",
    "\n",
    "const formattedPromptWithDate = await partialedPromptWithDate.format({\n",
    "  activity: \"æˆ‘ä»¬å»çˆ¬å±±\",\n",
    "});\n",
    "\n",
    "console.log(formattedPromptWithDate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e108f4-00ff-4419-8ffe-95d05de613a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/5/9 ä¸‹åˆå¥½!\n"
     ]
    }
   ],
   "source": [
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "function generateGreeting(timeOfDay) {\n",
    "  return () => {\n",
    "    const date = getCurrentDateStr()\n",
    "    switch (timeOfDay) {\n",
    "      case 'morning':\n",
    "        return date + ' æ—©ä¸Šå¥½';\n",
    "      case 'afternoon':\n",
    "        return date + ' ä¸‹åˆå¥½';\n",
    "      case 'evening':\n",
    "        return date + ' æ™šä¸Šå¥½';\n",
    "      default:\n",
    "        return date + ' ä½ å¥½';\n",
    "    }\n",
    "  };\n",
    "}\n",
    "\n",
    "const prompt = new PromptTemplate({\n",
    "  template: \"{greeting}!\",\n",
    "  inputVariables: [\"greeting\"],\n",
    "});\n",
    "\n",
    "const currentTimeOfDay = 'afternoon';\n",
    "const partialPrompt = await prompt.partial({\n",
    "  greeting: generateGreeting(currentTimeOfDay),\n",
    "});\n",
    "\n",
    "const formattedPrompt = await partialPrompt.format();\n",
    "\n",
    "console.log(formattedPrompt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6635326d-a407-4ba8-a800-942c085efc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { SystemMessagePromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const translateInstructionTemplate = SystemMessagePromptTemplate.fromTemplate(`ä½ æ˜¯ä¸€ä¸ªä¸“\n",
    "ä¸šçš„ç¿»è¯‘å‘˜ï¼Œä½ çš„ä»»åŠ¡æ˜¯å°†æ–‡æœ¬ä»{source_lang}ç¿»è¯‘æˆ{target_lang}ã€‚`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36cc113f-f948-49c5-bf52-62f1db8fed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { HumanMessagePromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const userQuestionTemplate = HumanMessagePromptTemplate.fromTemplate(\"è¯·ç¿»è¯‘è¿™å¥è¯ï¼š{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d116bff5-b070-4680-9f26-d9bb0d2f7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  translateInstructionTemplate,\n",
    "  userQuestionTemplate,\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc4334b0-1903-49b6-99c8-e0ad16326965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  SystemMessage {\n",
      "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "    lc_kwargs: {\n",
      "      content: \u001b[32m\"ä½ æ˜¯ä¸€ä¸ªä¸“\\nä¸šçš„ç¿»è¯‘å‘˜ï¼Œä½ çš„ä»»åŠ¡æ˜¯å°†æ–‡æœ¬ä»ä¸­æ–‡ç¿»è¯‘æˆæ³•è¯­ã€‚\"\u001b[39m,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "    content: \u001b[32m\"ä½ æ˜¯ä¸€ä¸ªä¸“\\nä¸šçš„ç¿»è¯‘å‘˜ï¼Œä½ çš„ä»»åŠ¡æ˜¯å°†æ–‡æœ¬ä»ä¸­æ–‡ç¿»è¯‘æˆæ³•è¯­ã€‚\"\u001b[39m,\n",
      "    name: \u001b[90mundefined\u001b[39m,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  HumanMessage {\n",
      "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "    lc_kwargs: {\n",
      "      content: \u001b[32m\"è¯·ç¿»è¯‘è¿™å¥è¯ï¼šä½ å¥½ï¼Œä¸–ç•Œ\"\u001b[39m,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "    content: \u001b[32m\"è¯·ç¿»è¯‘è¿™å¥è¯ï¼šä½ å¥½ï¼Œä¸–ç•Œ\"\u001b[39m,\n",
      "    name: \u001b[90mundefined\u001b[39m,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const formattedChatPrompt = await chatPrompt.formatMessages({\n",
    "  source_lang: \"ä¸­æ–‡\",\n",
    "  target_lang: \"æ³•è¯­\",\n",
    "  text: \"ä½ å¥½ï¼Œä¸–ç•Œ\",\n",
    "});\n",
    "\n",
    "console.log(formattedChatPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70832d36-f3a3-4eaf-8495-87b703176f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "const systemTemplate = \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘å‘˜ï¼Œä½ çš„ä»»åŠ¡æ˜¯å°†æ–‡æœ¬ä»{source_lang}ç¿»è¯‘æˆ{target_lang}ã€‚\";\n",
    "const humanTemplate = \"è¯·ç¿»è¯‘è¿™å¥è¯ï¼š{text}\";\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", systemTemplate],\n",
    "  [\"human\", humanTemplate],\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a84d49b-e589-4d07-b616-654815286ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La traduction est :\n",
      "\n",
      "Bonjour, monde !\n",
      "\n",
      "(Note : åœ¨æ³•è¯­ä¸­ï¼Œå¸¸è§çš„é—®å€™è¯­ä¸º\"bonjour\"ï¼Œè¡¨ç¤ºæ—©ä¸Šæˆ–ä¸‹åˆçš„é—®å€™ï¼Œè€Œä¸æ˜¯ç‰¹åˆ«å…³å¿ƒå¯¹æ–¹çš„æƒ…å†µã€‚ä½†æ˜¯ï¼Œå¦‚æœä½ æƒ³è¡¨è¾¾æ›´å‹å¥½çš„æ„æ€ï¼Œå¯ä»¥ä½¿ç”¨\"salut\"æˆ–\"hello\"ã€‚)\n",
      "\n",
      "å¦‚æœä½ æƒ³è¦æ›´å¤šçš„ç¿»è¯‘ï¼Œè¯·éšæ—¶æå‡ºè¯·æ±‚ï¼\n"
     ]
    }
   ],
   "source": [
    "import { load } from \"dotenv\";\n",
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const env = await load();\n",
    "const process = {\n",
    "    env\n",
    "}\n",
    "\n",
    "const outputPraser = new StringOutputParser();\n",
    "\n",
    "const chain = chatPrompt.pipe(ollama).pipe(outputPraser);\n",
    "\n",
    "const stream = await chain.invoke({\n",
    "  source_lang: \"ä¸­æ–‡\",\n",
    "  target_lang: \"æ³•è¯­\",\n",
    "  text: \"ä½ å¥½ï¼Œä¸–ç•Œ\",\n",
    "})\n",
    "\n",
    "console.log(stream);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dc6250c-80b0-450a-84e1-4ddbde7e2395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ç®¡å®¶ï¼Œä»Šå¤©æ˜¯ 2024/5/9ï¼Œç°åœ¨æ˜¯ æ—©ä¸Šï¼Œä½ çš„ä¸»äººçš„ä¿¡æ¯æ˜¯å§“åæ˜¯ å¼ ä¸‰, æ€§åˆ«æ˜¯ male, \n",
      "æ ¹æ®ä¸Šä¸‹æ–‡ï¼Œå®Œæˆä¸»äººçš„éœ€æ±‚\n",
      "\n",
      "æˆ‘æƒ³åƒ æ—©ä¸Š çš„ lemonã€‚ \n",
      "å†é‡å¤ä¸€éæˆ‘çš„ä¿¡æ¯ å§“åæ˜¯ å¼ ä¸‰, æ€§åˆ«æ˜¯ male\n"
     ]
    }
   ],
   "source": [
    "import {\n",
    "  PromptTemplate,\n",
    "  PipelinePromptTemplate,\n",
    "} from \"@langchain/core/prompts\";\n",
    "\n",
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "const fullPrompt = PromptTemplate.fromTemplate(`\n",
    "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ç®¡å®¶ï¼Œä»Šå¤©æ˜¯ {date}ï¼Œä½ çš„ä¸»äººçš„ä¿¡æ¯æ˜¯{info}, \n",
    "æ ¹æ®ä¸Šä¸‹æ–‡ï¼Œå®Œæˆä¸»äººçš„éœ€æ±‚\n",
    "{task}`);\n",
    "\n",
    "const datePrompt = PromptTemplate.fromTemplate(\"{date}ï¼Œç°åœ¨æ˜¯ {period}\")\n",
    "const periodPrompt = await datePrompt.partial({\n",
    "    date: getCurrentDateStr\n",
    "})\n",
    "\n",
    "const infoPrompt =  PromptTemplate.fromTemplate(\"å§“åæ˜¯ {name}, æ€§åˆ«æ˜¯ {gender}\");\n",
    "\n",
    "const taskPrompt = PromptTemplate.fromTemplate(`\n",
    "æˆ‘æƒ³åƒ {period} çš„ {food}ã€‚ \n",
    "å†é‡å¤ä¸€éæˆ‘çš„ä¿¡æ¯ {info}`);\n",
    "\n",
    "const composedPrompt = new PipelinePromptTemplate({\n",
    "  pipelinePrompts: [\n",
    "    {\n",
    "      name: \"date\",\n",
    "      prompt: periodPrompt,\n",
    "    },\n",
    "    {\n",
    "      name: \"info\",\n",
    "      prompt: infoPrompt,\n",
    "    },\n",
    "    {\n",
    "      name: \"task\",\n",
    "      prompt: taskPrompt,\n",
    "    },\n",
    "  ],\n",
    "  finalPrompt: fullPrompt,\n",
    "});\n",
    "\n",
    "const formattedPrompt = await composedPrompt.format({\n",
    "    period: \"æ—©ä¸Š\",\n",
    "    name: \"å¼ ä¸‰\",\n",
    "    gender: \"male\",\n",
    "    food: \"lemon\"\n",
    "});\n",
    "\n",
    "console.log(formattedPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "445b0d0c-9c3d-45da-b2dc-b2291abaff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StructuredOutputParser } from \"langchain/output_parsers\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const parser = StructuredOutputParser.fromNamesAndDescriptions({\n",
    "  answer: \"ç”¨æˆ·é—®é¢˜çš„ç­”æ¡ˆ\",\n",
    "  evidence: \"ä½ å›ç­”ç”¨æˆ·é—®é¢˜æ‰€ä¾æ®çš„ç­”æ¡ˆ\",\n",
    "  confidence: \"é—®é¢˜ç­”æ¡ˆçš„å¯ä¿¡åº¦è¯„åˆ†ï¼Œæ ¼å¼æ˜¯ç™¾åˆ†æ•°\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46835537-38c1-4417-8595-ca7fdd4fe5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  answer: \u001b[32m\"Leonardo da Vinci\"\u001b[39m,\n",
      "  evidence: \u001b[32m\"Leonardo da Vinci was an Italian polymath and one of the most famous artists in history. He is widel\"\u001b[39m... 60 more characters,\n",
      "  confidence: \u001b[32m\"99%\"\u001b[39m\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "\n",
    "const prompt = PromptTemplate.fromTemplate(\"å°½å¯èƒ½çš„å›ç­”ç”¨çš„é—®é¢˜ \\n{instructions} \\n{question}\")\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const chain = prompt.pipe(ollama).pipe(parser)\n",
    "\n",
    "const res = await chain.invoke({\n",
    "    question: \"è’™å¨œä¸½èçš„ä½œè€…æ˜¯è°ï¼Ÿæ˜¯ä»€ä¹ˆæ—¶å€™ç»˜åˆ¶çš„\",\n",
    "    instructions: parser.getFormatInstructions()\n",
    "})\n",
    "                               \n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45d23648-9483-4c26-8e20-245c60ef29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
     ]
    }
   ],
   "source": [
    "import { CommaSeparatedListOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const parser = new CommaSeparatedListOutputParser();\n",
    "\n",
    "console.log(parser.getFormatInstructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "857591ab-8013-4e7e-a4a0-02e911a38c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"Google\"\u001b[39m, \u001b[32m\"Facebook\"\u001b[39m, \u001b[32m\"Amazon\"\u001b[39m ]\n"
     ]
    }
   ],
   "source": [
    "const prompt = PromptTemplate.fromTemplate(\"åˆ—å‡º3ä¸ª {country} çš„è‘—åçš„äº’è”ç½‘å…¬å¸.\\n{instructions}\")\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "    \n",
    "const chain = prompt.pipe(ollama).pipe(parser)\n",
    "\n",
    "const response = await chain.invoke({\n",
    "    country: \"America\",\n",
    "    instructions: parser.getFormatInstructions(),\n",
    "});\n",
    "console.log(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8448f4e-bbe6-49e5-9f09-fc52cf62639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "const schema = z.object({\n",
    "  answer:  z.string().describe(\"ç”¨æˆ·é—®é¢˜çš„ç­”æ¡ˆ\"),\n",
    "  confidence: z.number().min(0).max(100).describe(\"é—®é¢˜ç­”æ¡ˆçš„å¯ä¿¡åº¦è¯„åˆ†ï¼Œæ»¡åˆ† 100\")\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d191c888-ecc4-4316-8c6d-71d6c4e8489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ answer: \u001b[32m\"Leonardo da Vinci\"\u001b[39m, confidence: \u001b[33m95\u001b[39m }\n"
     ]
    }
   ],
   "source": [
    "const parser = StructuredOutputParser.fromZodSchema(schema);\n",
    "const prompt = PromptTemplate.fromTemplate(\"å°½å¯èƒ½çš„å›ç­”ç”¨çš„é—®é¢˜ \\n{instructions} \\n{question}\")\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const chain = prompt.pipe(ollama).pipe(parser)\n",
    "const res = await chain.invoke({\n",
    "    question: \"è’™å¨œä¸½èçš„ä½œè€…æ˜¯è°ï¼Ÿæ˜¯ä»€ä¹ˆæ—¶å€™ç»˜åˆ¶çš„\",\n",
    "    instructions: parser.getFormatInstructions()\n",
    "})\n",
    "                               \n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a388a49b-f1f3-4673-bade-df96e2d46027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { OutputFixingParser } from \"langchain/output_parsers\";\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const fixParser = OutputFixingParser.fromLLM(ollama, parser);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a668be9-04b6-4144-b991-b29ef7f753a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ answer: \u001b[32m\"è’™å¨œä¸½èçš„ä½œè€…æ˜¯è¾¾èŠ¬å¥‡ï¼Œå¤§çº¦åœ¨16ä¸–çºªåˆæœŸï¼ˆ1503å¹´è‡³1506å¹´ä¹‹é—´ï¼‰å¼€å§‹ç»˜åˆ¶ã€‚\"\u001b[39m, confidence: \u001b[33m50\u001b[39m }\n"
     ]
    }
   ],
   "source": [
    "const wrongOutput = {\n",
    "  \"answer\": \"è’™å¨œä¸½èçš„ä½œè€…æ˜¯è¾¾èŠ¬å¥‡ï¼Œå¤§çº¦åœ¨16ä¸–çºªåˆæœŸï¼ˆ1503å¹´è‡³1506å¹´ä¹‹é—´ï¼‰å¼€å§‹ç»˜åˆ¶ã€‚\",\n",
    "  \"sources\": \"90%\" \n",
    "};\n",
    "\n",
    "const fixParser = OutputFixingParser.fromLLM(ollama, parser);\n",
    "const output = await fixParser.parse(JSON.stringify(wrongOutput));\n",
    "console.log(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9d4a5-d537-49bc-82ce-742db13dc2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
