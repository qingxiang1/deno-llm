{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92cbe80b-02a4-4943-84de-b8b7f12f4677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me tell you a story.\n",
      "\n",
      "Once upon a time, in a small village nestled in the mountains, there lived a young girl named Ling. She was known throughout the village for her kind heart and her love of animals.\n",
      "\n",
      "One winter morning, Ling woke up to find that a big storm had rolled in overnight. The wind howled and the snow fell in thick, heavy flakes. Ling looked out the window and saw that the villagers were struggling to make their way through the drifts.\n",
      "\n",
      "Without hesitation, Ling grabbed her warmest coat and set out into the storm. She trudged through the snow, her eyes scanning the ground for any sign of life. As she walked, she noticed a small bird perched on a branch, shivering in the cold.\n",
      "\n",
      "Ling's heart went out to the little creature. She knew that if she didn't help it soon, the bird might not make it through the night. So, she carefully scooped up some snow and molded it into a warm ball. Then, she gently placed the bird on top of the ball, making sure it was cozy and safe.\n",
      "\n",
      "As she stood there, she heard a faint mewling sound coming from behind a nearby pile of snow. Ling's ears perked up, and she quickly cleared away the snow to reveal a tiny kitten, shivering with fear and cold.\n",
      "\n",
      "Without thinking twice, Ling scooped up the kitten and cradled it in her arms. She then carefully wrapped it in some extra cloth and tucked it under her coat for warmth. As she walked back to her village, the wind and snow howling around her, she sang a soft little tune to keep both the bird and the kitten calm.\n",
      "\n",
      "When she arrived at her home, she gently placed the bird on a windowsill, where it could warm up and find some food. The kitten, meanwhile, snuggled up beside her on the couch, purring contentedly.\n",
      "\n",
      "Word spread quickly throughout the village about Ling's kindness. People began to call her \"The Snow Angel\" because of her selfless actions during the storm. From that day forward, whenever anyone in the village needed help or comfort, they would turn to Ling for support and guidance.\n",
      "\n",
      "And as for the bird and the kitten? They became her closest friends, often perching on her windowsill or curling up beside her at night, reminding her of the power of kindness and compassion.\n"
     ]
    }
   ],
   "source": [
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const simpleChain = ollama.pipe(outputPrase)\n",
    "\n",
    "const stream = await simpleChain.invoke([\n",
    "     new HumanMessage(\"讲个故事\")\n",
    "])\n",
    "\n",
    "console.log(stream);\n",
    "\n",
    "// const stream = await simpleChain.stream([\n",
    "//      new HumanMessage(\"Tell me a joke\")\n",
    "// ])\n",
    "// for await (const chunk of stream){\n",
    "//     console.log(chunk)\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282ca258-7640-4085-ab68-28064a1de83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const greetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [],\n",
    "  template: \"hello world\",\n",
    "});\n",
    "const formattedGreetingPrompt = await greetingPrompt.format();\n",
    "\n",
    "console.log(formattedGreetingPrompt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d20103-8adb-4d1a-9ba7-120ed7216d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good morning, Kai {test}\n"
     ]
    }
   ],
   "source": [
    "const multiVariableGreetingPrompt = new PromptTemplate({\n",
    "  inputVariables: [\"timeOfDay\", \"name\"],\n",
    "  template: \"good {timeOfDay}, {name} {{test}}\",\n",
    "});\n",
    "const formattedMultiVariableGreeting = await multiVariableGreetingPrompt.format({\n",
    "  timeOfDay: \"morning\",\n",
    "  name: \"Kai\",\n",
    "});\n",
    "\n",
    "console.log(formattedMultiVariableGreeting);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86555c54-cc7b-4541-b337-6e66083bd503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"timeOfDay\"\u001b[39m, \u001b[32m\"name\"\u001b[39m ]\n",
      "good morning, Kai\n"
     ]
    }
   ],
   "source": [
    "const autoInferTemplate = PromptTemplate.fromTemplate(\"good {timeOfDay}, {name}\");\n",
    "console.log(autoInferTemplate.inputVariables);\n",
    "\n",
    "const formattedAutoInferTemplate = await autoInferTemplate.format({\n",
    "  timeOfDay: \"morning\",\n",
    "  name: \"Kai\",\n",
    "});\n",
    "console.log(formattedAutoInferTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7def3380-cfc7-49f0-9529-9e0a478550cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天是2024/5/9，我们去爬山。\n"
     ]
    }
   ],
   "source": [
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "const promptWithDate = new PromptTemplate({\n",
    "  template: \"今天是{date}，{activity}。\",\n",
    "  inputVariables: [\"date\", \"activity\"],\n",
    "});\n",
    "\n",
    "const partialedPromptWithDate = await promptWithDate.partial({\n",
    "  date: getCurrentDateStr,\n",
    "});\n",
    "\n",
    "const formattedPromptWithDate = await partialedPromptWithDate.format({\n",
    "  activity: \"我们去爬山\",\n",
    "});\n",
    "\n",
    "console.log(formattedPromptWithDate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e108f4-00ff-4419-8ffe-95d05de613a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/5/9 下午好!\n"
     ]
    }
   ],
   "source": [
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "function generateGreeting(timeOfDay) {\n",
    "  return () => {\n",
    "    const date = getCurrentDateStr()\n",
    "    switch (timeOfDay) {\n",
    "      case 'morning':\n",
    "        return date + ' 早上好';\n",
    "      case 'afternoon':\n",
    "        return date + ' 下午好';\n",
    "      case 'evening':\n",
    "        return date + ' 晚上好';\n",
    "      default:\n",
    "        return date + ' 你好';\n",
    "    }\n",
    "  };\n",
    "}\n",
    "\n",
    "const prompt = new PromptTemplate({\n",
    "  template: \"{greeting}!\",\n",
    "  inputVariables: [\"greeting\"],\n",
    "});\n",
    "\n",
    "const currentTimeOfDay = 'afternoon';\n",
    "const partialPrompt = await prompt.partial({\n",
    "  greeting: generateGreeting(currentTimeOfDay),\n",
    "});\n",
    "\n",
    "const formattedPrompt = await partialPrompt.format();\n",
    "\n",
    "console.log(formattedPrompt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6635326d-a407-4ba8-a800-942c085efc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { SystemMessagePromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const translateInstructionTemplate = SystemMessagePromptTemplate.fromTemplate(`你是一个专\n",
    "业的翻译员，你的任务是将文本从{source_lang}翻译成{target_lang}。`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36cc113f-f948-49c5-bf52-62f1db8fed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { HumanMessagePromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const userQuestionTemplate = HumanMessagePromptTemplate.fromTemplate(\"请翻译这句话：{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d116bff5-b070-4680-9f26-d9bb0d2f7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  translateInstructionTemplate,\n",
    "  userQuestionTemplate,\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc4334b0-1903-49b6-99c8-e0ad16326965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  SystemMessage {\n",
      "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "    lc_kwargs: {\n",
      "      content: \u001b[32m\"你是一个专\\n业的翻译员，你的任务是将文本从中文翻译成法语。\"\u001b[39m,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "    content: \u001b[32m\"你是一个专\\n业的翻译员，你的任务是将文本从中文翻译成法语。\"\u001b[39m,\n",
      "    name: \u001b[90mundefined\u001b[39m,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  HumanMessage {\n",
      "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "    lc_kwargs: {\n",
      "      content: \u001b[32m\"请翻译这句话：你好，世界\"\u001b[39m,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "    content: \u001b[32m\"请翻译这句话：你好，世界\"\u001b[39m,\n",
      "    name: \u001b[90mundefined\u001b[39m,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const formattedChatPrompt = await chatPrompt.formatMessages({\n",
    "  source_lang: \"中文\",\n",
    "  target_lang: \"法语\",\n",
    "  text: \"你好，世界\",\n",
    "});\n",
    "\n",
    "console.log(formattedChatPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70832d36-f3a3-4eaf-8495-87b703176f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "const systemTemplate = \"你是一个专业的翻译员，你的任务是将文本从{source_lang}翻译成{target_lang}。\";\n",
    "const humanTemplate = \"请翻译这句话：{text}\";\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", systemTemplate],\n",
    "  [\"human\", humanTemplate],\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a84d49b-e589-4d07-b616-654815286ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La traduction est :\n",
      "\n",
      "Bonjour, monde !\n",
      "\n",
      "(Note : 在法语中，常见的问候语为\"bonjour\"，表示早上或下午的问候，而不是特别关心对方的情况。但是，如果你想表达更友好的意思，可以使用\"salut\"或\"hello\"。)\n",
      "\n",
      "如果你想要更多的翻译，请随时提出请求！\n"
     ]
    }
   ],
   "source": [
    "import { load } from \"dotenv\";\n",
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const env = await load();\n",
    "const process = {\n",
    "    env\n",
    "}\n",
    "\n",
    "const outputPraser = new StringOutputParser();\n",
    "\n",
    "const chain = chatPrompt.pipe(ollama).pipe(outputPraser);\n",
    "\n",
    "const stream = await chain.invoke({\n",
    "  source_lang: \"中文\",\n",
    "  target_lang: \"法语\",\n",
    "  text: \"你好，世界\",\n",
    "})\n",
    "\n",
    "console.log(stream);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dc6250c-80b0-450a-84e1-4ddbde7e2395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你是一个智能管家，今天是 2024/5/9，现在是 早上，你的主人的信息是姓名是 张三, 性别是 male, \n",
      "根据上下文，完成主人的需求\n",
      "\n",
      "我想吃 早上 的 lemon。 \n",
      "再重复一遍我的信息 姓名是 张三, 性别是 male\n"
     ]
    }
   ],
   "source": [
    "import {\n",
    "  PromptTemplate,\n",
    "  PipelinePromptTemplate,\n",
    "} from \"@langchain/core/prompts\";\n",
    "\n",
    "const getCurrentDateStr = () => {\n",
    "  return new Date().toLocaleDateString();\n",
    "};\n",
    "\n",
    "const fullPrompt = PromptTemplate.fromTemplate(`\n",
    "你是一个智能管家，今天是 {date}，你的主人的信息是{info}, \n",
    "根据上下文，完成主人的需求\n",
    "{task}`);\n",
    "\n",
    "const datePrompt = PromptTemplate.fromTemplate(\"{date}，现在是 {period}\")\n",
    "const periodPrompt = await datePrompt.partial({\n",
    "    date: getCurrentDateStr\n",
    "})\n",
    "\n",
    "const infoPrompt =  PromptTemplate.fromTemplate(\"姓名是 {name}, 性别是 {gender}\");\n",
    "\n",
    "const taskPrompt = PromptTemplate.fromTemplate(`\n",
    "我想吃 {period} 的 {food}。 \n",
    "再重复一遍我的信息 {info}`);\n",
    "\n",
    "const composedPrompt = new PipelinePromptTemplate({\n",
    "  pipelinePrompts: [\n",
    "    {\n",
    "      name: \"date\",\n",
    "      prompt: periodPrompt,\n",
    "    },\n",
    "    {\n",
    "      name: \"info\",\n",
    "      prompt: infoPrompt,\n",
    "    },\n",
    "    {\n",
    "      name: \"task\",\n",
    "      prompt: taskPrompt,\n",
    "    },\n",
    "  ],\n",
    "  finalPrompt: fullPrompt,\n",
    "});\n",
    "\n",
    "const formattedPrompt = await composedPrompt.format({\n",
    "    period: \"早上\",\n",
    "    name: \"张三\",\n",
    "    gender: \"male\",\n",
    "    food: \"lemon\"\n",
    "});\n",
    "\n",
    "console.log(formattedPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "445b0d0c-9c3d-45da-b2dc-b2291abaff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StructuredOutputParser } from \"langchain/output_parsers\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const parser = StructuredOutputParser.fromNamesAndDescriptions({\n",
    "  answer: \"用户问题的答案\",\n",
    "  evidence: \"你回答用户问题所依据的答案\",\n",
    "  confidence: \"问题答案的可信度评分，格式是百分数\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46835537-38c1-4417-8595-ca7fdd4fe5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  answer: \u001b[32m\"Leonardo da Vinci\"\u001b[39m,\n",
      "  evidence: \u001b[32m\"Leonardo da Vinci was an Italian polymath and one of the most famous artists in history. He is widel\"\u001b[39m... 60 more characters,\n",
      "  confidence: \u001b[32m\"99%\"\u001b[39m\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "\n",
    "const prompt = PromptTemplate.fromTemplate(\"尽可能的回答用的问题 \\n{instructions} \\n{question}\")\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const chain = prompt.pipe(ollama).pipe(parser)\n",
    "\n",
    "const res = await chain.invoke({\n",
    "    question: \"蒙娜丽莎的作者是谁？是什么时候绘制的\",\n",
    "    instructions: parser.getFormatInstructions()\n",
    "})\n",
    "                               \n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45d23648-9483-4c26-8e20-245c60ef29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
     ]
    }
   ],
   "source": [
    "import { CommaSeparatedListOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const parser = new CommaSeparatedListOutputParser();\n",
    "\n",
    "console.log(parser.getFormatInstructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "857591ab-8013-4e7e-a4a0-02e911a38c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m\"Google\"\u001b[39m, \u001b[32m\"Facebook\"\u001b[39m, \u001b[32m\"Amazon\"\u001b[39m ]\n"
     ]
    }
   ],
   "source": [
    "const prompt = PromptTemplate.fromTemplate(\"列出3个 {country} 的著名的互联网公司.\\n{instructions}\")\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "    \n",
    "const chain = prompt.pipe(ollama).pipe(parser)\n",
    "\n",
    "const response = await chain.invoke({\n",
    "    country: \"America\",\n",
    "    instructions: parser.getFormatInstructions(),\n",
    "});\n",
    "console.log(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8448f4e-bbe6-49e5-9f09-fc52cf62639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "const schema = z.object({\n",
    "  answer:  z.string().describe(\"用户问题的答案\"),\n",
    "  confidence: z.number().min(0).max(100).describe(\"问题答案的可信度评分，满分 100\")\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d191c888-ecc4-4316-8c6d-71d6c4e8489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ answer: \u001b[32m\"Leonardo da Vinci\"\u001b[39m, confidence: \u001b[33m95\u001b[39m }\n"
     ]
    }
   ],
   "source": [
    "const parser = StructuredOutputParser.fromZodSchema(schema);\n",
    "const prompt = PromptTemplate.fromTemplate(\"尽可能的回答用的问题 \\n{instructions} \\n{question}\")\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const chain = prompt.pipe(ollama).pipe(parser)\n",
    "const res = await chain.invoke({\n",
    "    question: \"蒙娜丽莎的作者是谁？是什么时候绘制的\",\n",
    "    instructions: parser.getFormatInstructions()\n",
    "})\n",
    "                               \n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a388a49b-f1f3-4673-bade-df96e2d46027",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "Ollama is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: Ollama is not defined",
      "    at <anonymous>:2:16"
     ]
    }
   ],
   "source": [
    "import { OutputFixingParser } from \"langchain/output_parsers\";\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"llama3\", \n",
    "});\n",
    "\n",
    "const fixParser = OutputFixingParser.fromLLM(ollama, parser);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a668be9-04b6-4144-b991-b29ef7f753a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "OutputFixingParser is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: OutputFixingParser is not defined",
      "    at <anonymous>:5:19"
     ]
    }
   ],
   "source": [
    "const wrongOutput = {\n",
    "  \"answer\": \"蒙娜丽莎的作者是达芬奇，大约在16世纪初期（1503年至1506年之间）开始绘制。\",\n",
    "  \"sources\": \"90%\" \n",
    "};\n",
    "\n",
    "const fixParser = OutputFixingParser.fromLLM(ollama, parser);\n",
    "const output = await fixParser.parse(JSON.stringify(wrongOutput));\n",
    "console.log(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9d4a5-d537-49bc-82ce-742db13dc2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
